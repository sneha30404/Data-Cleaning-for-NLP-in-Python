# Data-Cleaning-for-NLP-in-Python

## ðŸ“Œ Overview
This repository contains essential techniques for **data cleaning in Natural Language Processing (NLP)** using Python. The provided Jupyter notebooks cover various preprocessing steps to clean and prepare textual data for NLP tasks.

## ðŸ›  Topics Covered
- **Text Normalization** â€“ Lowercasing, removing special characters, and expanding contractions.  
- **Tokenization** â€“ Splitting text into meaningful units (words, sentences).  
- **Stopword Removal** â€“ Filtering out common words like *the*, *is*, *and*, etc.  
- **Stemming & Lemmatization** â€“ Reducing words to their base forms.  
- **Handling Punctuation & Special Characters** â€“ Cleaning unnecessary symbols.  
- **Removing Duplicates & Noise** â€“ Eliminating unwanted data like HTML tags, numbers, or extra spaces.  

## ðŸ”§ Installation
To use this repository, install the required dependencies:

```sh
pip install pandas nltk re numpy
```

